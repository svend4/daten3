version: '3.8'

services:
  # ========================================================================
  # ML Services
  # ========================================================================
  
  # BERT Model Server
  bert-server:
    image: huggingface/transformers-pytorch-cpu:latest
    container_name: ios-bert-server
    restart: unless-stopped
    
    working_dir: /app
    
    command: >
      python -m uvicorn server:app
      --host 0.0.0.0
      --port 8001
      --workers 4
    
    ports:
      - "8001:8001"
    
    volumes:
      - ./ml_services/bert:/app
      - bert-models:/models
      - bert-cache:/root/.cache/huggingface
    
    environment:
      - MODEL_NAME=deepset/gbert-large
      - MODEL_CACHE_DIR=/models
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      - MAX_LENGTH=512
      - BATCH_SIZE=8
    
    networks:
      - ios-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

  # GPU-accelerated BERT (optional)
  bert-gpu:
    image: huggingface/transformers-pytorch-gpu:latest
    container_name: ios-bert-gpu
    restart: unless-stopped
    
    working_dir: /app
    
    command: >
      python -m uvicorn server:app
      --host 0.0.0.0
      --port 8002
      --workers 2
    
    ports:
      - "8002:8002"
    
    volumes:
      - ./ml_services/bert:/app
      - bert-models:/models
      - bert-cache:/root/.cache/huggingface
    
    environment:
      - MODEL_NAME=deepset/gbert-large
      - MODEL_CACHE_DIR=/models
      - USE_GPU=true
      - CUDA_VISIBLE_DEVICES=0
    
    networks:
      - ios-network
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    profiles:
      - gpu

  # Sentence Transformers Service
  sentence-transformers:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    container_name: ios-sentence-transformers
    restart: unless-stopped
    
    command: --model-id sentence-transformers/paraphrase-multilingual-mpnet-base-v2
    
    ports:
      - "8003:80"
    
    volumes:
      - sentence-transformers-data:/data
    
    networks:
      - ios-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: ios-qdrant
    restart: unless-stopped
    
    ports:
      - "6333:6333"
      - "6334:6334"
    
    volumes:
      - qdrant-storage:/qdrant/storage
      - ./ml_services/qdrant/config.yaml:/qdrant/config/production.yaml
    
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    
    networks:
      - ios-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  bert-models:
    driver: local
  bert-cache:
    driver: local
  sentence-transformers-data:
    driver: local
  qdrant-storage:
    driver: local

networks:
  ios-network:
    external: true